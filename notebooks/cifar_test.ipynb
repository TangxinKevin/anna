{
 "metadata": {
  "name": "cifar_test"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "import os", 
      "from time import time", 
      "from datetime import datetime", 
      "import cPickle", 
      "import numpy", 
      "import matplotlib.pyplot as pyplot", 
      "import theano", 
      "import theano.tensor as T", 
      "from theano.sandbox.cuda.basic_ops import gpu_contiguous", 
      "", 
      "import pylearn2.datasets.cifar10 as cifar10", 
      "#from pylearn2.sandbox.cuda_convnet.filter_acts import FilterActs", 
      "#from pylearn2.sandbox.cuda_convnet.filter_acts import ImageActs", 
      "", 
      "from layers import layers, cc_layers", 
      "", 
      "theano.config.floatX = 'float32'"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "def fix(x):", 
      "    r = x[0,:,:]", 
      "    g = x[1,:,:]", 
      "    b = x[2,:,:]", 
      "    return numpy.dstack((r,g,b))", 
      "", 
      "def save_checkpoint(all_parameters):", 
      "    model_check = [param.get_value() for param in all_parameters]", 
      "    tt = datetime.now()", 
      "    time_string = tt.strftime('%mm-%dd-%Hh-%Mm-%Ss')", 
      "    check_name = 'cifar10-%s.pkl' % time_string", 
      "    path_name = os.path.join('/experiments/cifar10-2/', check_name)", 
      "", 
      "    print 'Saving model checkpoint to: %s' % path_name", 
      "    f = open(path_name, 'wb')", 
      "    cPickle.dump(model_check, f)", 
      "    f.close()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "class Model():", 
      "    input = cc_layers.CudaConvnetInput2DLayer(128, 3, 32, 32)", 
      "    conv1 = cc_layers.CudaConvnetConv2DLayer(input, ", 
      "                                             n_filters=32,", 
      "                                             filter_size=6,", 
      "                                             weights_std=0.01,", 
      "                                             init_bias_value=0.1)", 
      "    conv2 = cc_layers.CudaConvnetConv2DLayer(conv1, ", 
      "                                             n_filters=64,", 
      "                                             filter_size=3,", 
      "                                             weights_std=0.01,", 
      "                                             init_bias_value=0.1)", 
      "    deconv3 = cc_layers.CudaConvnetDeconv2DLayer(conv2,", 
      "                                                 n_channels=32,", 
      "                                                 filter_size=3,", 
      "                                                 weights_std=0.01,", 
      "                                                 init_bias_value=0.1)", 
      "    deconv4 = cc_layers.CudaConvnetDeconv2DLayer(deconv3,", 
      "                                                 n_channels=3,", 
      "                                                 filter_size=6,", 
      "                                                 weights_std=0.01,", 
      "                                                 init_bias_value=0.1)", 
      "    ", 
      "    def __init__(self):", 
      "        self.all_parameters_symbol = layers.all_parameters(self._get_output_layer())", 
      "    ", 
      "        # can switch to gen_updates_regular_momentum", 
      "        self.learning_rate_symbol = theano.shared(np.array(0.01, dtype=theano.config.floatX))", 
      "        self.updates_symbol = layers.gen_updates_sgd(self._get_cost_symbol(),", 
      "                                                     self.all_parameters_symbol,", 
      "                                                     learning_rate=self.learning_rate_symbol)", 
      "", 
      "        self.train_func = theano.function([self._get_input_symbol()],", 
      "                                           self._get_cost_symbol(),", 
      "                                           updates=self.updates_symbol)", 
      "        self.eval_func = theano.function([self._get_input_symbol()],", 
      "                                         self._get_cost_symbol())", 
      "        self.prediction_func = theano.function([self._get_input_symbol()],", 
      "                                          self._get_output_symbol())", 
      "    def _get_input_symbol(self):", 
      "        return self.input.output()", 
      "    ", 
      "    def _get_output_symbol(self):", 
      "        return self.deconv4.output()", 
      "    ", 
      "    def _get_cost_symbol(self):", 
      "        input = self._get_input_symbol()", 
      "        output = self._get_output_symbol()", 
      "        cost = T.mean((output - input) ** 2)", 
      "        return cost", 
      "", 
      "    def _get_output_layer(self):", 
      "        return self.deconv4", 
      "    ", 
      "    def train(self, batch):", 
      "        return self.train_func(batch)", 
      "    ", 
      "    def eval(self, batch):", 
      "        return self.eval_func(batch)", 
      "", 
      "    def prediction(self, batch):", 
      "        return self.prediction_func(batch)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "class Monitor(object):", 
      "    errors = []", 
      "    times = []", 
      "    big_errors = []", 
      "    big_times = []", 
      "", 
      "    def __init__(self, model, step_number=0, best=1, short_steps=10, long_steps=50):", 
      "        self.step_number = step_number", 
      "        self.best = best", 
      "        self.short_steps = short_steps", 
      "        self.long_steps = long_steps", 
      "        self.model = model", 
      "        ", 
      "    def start(self):", 
      "        self.tic = time()", 
      "    ", 
      "    def stop(self, error):", 
      "        self.toc = time()", 
      "        _time = self.toc-self.tic", 
      "        self.errors.append(error)", 
      "        self.times.append(_time)", 
      "        self.big_errors.append(error)", 
      "        self.big_times.append(_time)", 
      "        if self.step_number % self.long_steps == 0:", 
      "            mean_error = numpy.mean(self.big_errors)", 
      "            mean_time = numpy.mean(self.big_times)", 
      "            print '*%d, train error: %.3f, time: %.2f' % (self.step_number, mean_error, mean_time)", 
      "            self.big_errors = []", 
      "            self.big_times = []", 
      "            if mean_error < self.best:", 
      "                self.best = mean_error", 
      "                save_checkpoint(self.model.all_parameters_symbol)", 
      "        if self.step_number % self.short_steps == 0:", 
      "            mean_error = numpy.mean(self.errors)", 
      "            mean_time = numpy.mean(self.times)", 
      "            print '%d, train error: %.3f, time: %.2f' % (self.step_number, mean_error, mean_time)", 
      "            self.errors = []", 
      "            self.times = []", 
      "        self.step_number += 1", 
      "        ", 
      "class Evaluator(object):", 
      "    def __init__(self, model, dataset, steps=100):", 
      "        self.step_number = 1", 
      "        self.steps = steps", 
      "        self.model = model", 
      "        self.dataset = dataset", 
      "    ", 
      "    def run(self):", 
      "        iterator = self.dataset.iterator(mode='sequential', batch_size=128, topo=True)", 
      "        errors = []", 
      "        if self.step_number % self.steps == 0:", 
      "            tic = time()", 
      "            for batch in iterator:", 
      "                error = self.model.eval(batch)", 
      "                errors.append(error)", 
      "            toc = time()", 
      "            _time = toc-tic", 
      "            mean_error = numpy.mean(errors)", 
      "            print '%d, test error: %.3f, time: %.2f' % (self.step_number, mean_error, _time)", 
      "        self.step_number += 1"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 27
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "model = Model()", 
      "monitor = Monitor(model)", 
      "", 
      "train_dataset = cifar10.CIFAR10(which_set='train',", 
      "                                rescale=True,", 
      "                                axes=['c', 0, 1, 'b']", 
      "                                )", 
      "test_dataset = cifar10.CIFAR10(which_set='test',", 
      "                               rescale=True,", 
      "                               axes=['c', 0, 1, 'b']", 
      "                               )", 
      "train_iterator = train_dataset.iterator(mode='random_uniform', batch_size=128, num_batches=100000, topo=True)", 
      "", 
      "evaluator = Evaluator(model, test_dataset, steps=1000)", 
      "", 
      "for batch in train_iterator:", 
      "    monitor.start()", 
      "    error = model.train(batch)", 
      "    monitor.stop(error)", 
      "    evaluator.run()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_1"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_2"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_3"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_5"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/test_batch"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_1"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_2"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_3"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/data_batch_5"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "loading file /media/hd1/data/cifar10/cifar-10-batches-py/test_batch"
       ]
      }, 
      {
       "ename": "KeyboardInterrupt", 
       "evalue": "", 
       "output_type": "pyerr", 
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", 
        "\u001b[0;32m/home/paine1/unsupervised_experiments/<ipython-input-28-332da72b84e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
        "\u001b[0;32m/home/paine1/unsupervised_experiments/<ipython-input-4-39f5852bc111>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
        "\u001b[0;32m/home/paine1/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "*0, train error: 0.204, time: 0.28", 
        "Saving model checkpoint to: /experiments/cifar10-2/cifar10-09m-09d-15h-38m-28s.pkl", 
        "0, train error: 0.204, time: 0.28"
       ]
      }
     ], 
     "prompt_number": 28
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "i = numpy.random.randint(128)", 
      "pyplot.imshow(numpy.hstack((x[2,:,:,i],x_hat[2,:,:,i])))", 
      "#pyplot.imshow(x[2,:,:,100]-x_hat[2,:,:,100])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 216, 
       "text": [
        "<matplotlib.image.AxesImage at 0xb5fb790>"
       ]
      }
     ], 
     "prompt_number": 216
    }
   ]
  }
 ]
}